name: ZoneWise Continuous Extraction

on:
  schedule:
    # Run daily at 11 PM EST (4 AM UTC)
    - cron: '0 4 * * *'
  workflow_dispatch:
    inputs:
      jurisdiction:
        description: 'Specific jurisdiction to extract (leave empty for all)'
        required: false
        default: ''
      force_update:
        description: 'Force update even if no changes detected'
        required: false
        default: 'false'

env:
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}

jobs:
  extract-zoning-data:
    name: Extract Zoning Data
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install httpx
      
      - name: Run extraction
        id: extract
        run: |
          python3 << 'EOF'
          import os
          import sys
          import json
          
          # Add the extractor to path
          sys.path.insert(0, 'src/extractors')
          
          from zonewise_mcp_server import ZoneWiseExtractor, BREVARD_JURISDICTIONS
          from supabase_integration import ZoneWiseSupabase
          
          # Get inputs
          jurisdiction = os.environ.get('INPUT_JURISDICTION', '').strip()
          force_update = os.environ.get('INPUT_FORCE_UPDATE', 'false').lower() == 'true'
          
          print("="*60)
          print("ZoneWise Continuous Extraction")
          print("="*60)
          
          extractor = ZoneWiseExtractor()
          supabase = ZoneWiseSupabase()
          
          # Get existing content hashes for change detection
          existing_hashes = supabase.get_content_hashes() if not force_update else {}
          print(f"Existing hashes: {len(existing_hashes)} jurisdictions")
          
          results = {}
          changes = []
          
          # Determine which jurisdictions to process
          if jurisdiction:
              jurisdictions_to_process = [jurisdiction]
          else:
              jurisdictions_to_process = list(BREVARD_JURISDICTIONS.keys())
          
          for jur in jurisdictions_to_process:
              print(f"\nProcessing {jur}...")
              
              try:
                  # Extract districts
                  districts = extractor.extract_jurisdiction(jur)
                  
                  if districts:
                      # Check for changes
                      new_hash = districts[0].content_hash if districts else None
                      old_hash = existing_hashes.get(jur.replace('_', ' ').title())
                      
                      if new_hash and new_hash != old_hash:
                          changes.append(jur)
                          print(f"  ‚ö†Ô∏è Changes detected in {jur}")
                      
                      # Store in Supabase
                      district_dicts = [d.__dict__ for d in districts]
                      result = supabase.upsert_districts(district_dicts)
                      
                      results[jur] = len(districts)
                      print(f"  ‚úÖ Extracted {len(districts)} districts")
                  else:
                      results[jur] = 0
                      print(f"  ‚ö†Ô∏è No districts extracted")
                      
              except Exception as e:
                  print(f"  ‚ùå Error: {e}")
                  results[jur] = 0
          
          # Log the run
          supabase.log_extraction_run(results)
          
          # Summary
          print("\n" + "="*60)
          print("EXTRACTION SUMMARY")
          print("="*60)
          print(f"Jurisdictions processed: {len(results)}")
          print(f"Total districts extracted: {sum(results.values())}")
          print(f"Changes detected: {len(changes)}")
          if changes:
              print(f"  Changed jurisdictions: {', '.join(changes)}")
          
          # Set outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"total_districts={sum(results.values())}\n")
              f.write(f"changes_detected={len(changes) > 0}\n")
              f.write(f"changed_jurisdictions={','.join(changes)}\n")
          
          extractor.close()
          supabase.close()
          
          print("\n‚úÖ Extraction complete!")
          EOF
        env:
          INPUT_JURISDICTION: ${{ github.event.inputs.jurisdiction }}
          INPUT_FORCE_UPDATE: ${{ github.event.inputs.force_update }}
      
      - name: Notify on changes
        if: steps.extract.outputs.changes_detected == 'true'
        run: |
          echo "üîî Zoning code changes detected!"
          echo "Changed jurisdictions: ${{ steps.extract.outputs.changed_jurisdictions }}"
          # TODO: Add Slack/email notification
      
      - name: Upload extraction results
        uses: actions/upload-artifact@v4
        with:
          name: extraction-results-${{ github.run_number }}
          path: /tmp/zonewise_*.json
          retention-days: 30
          if-no-files-found: ignore

  notify-on-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: extract-zoning-data
    if: failure()
    
    steps:
      - name: Send failure notification
        run: |
          echo "‚ùå ZoneWise extraction failed!"
          # TODO: Add notification webhook
